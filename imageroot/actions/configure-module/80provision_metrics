#!/usr/bin/env python3

#
# Copyright (C) 2025 Nethesis S.r.l.
# SPDX-License-Identifier: GPL-3.0-or-later
#

import os
import yaml
import agent

module_id = os.environ['MODULE_ID']
agent_id = os.environ['AGENT_ID']
node_id = int(os.environ['NODE_ID'])
rdb_ro = agent.redis_connect()
# below query must be executed on a non-privileged connection
ip_address = rdb_ro.hget(f'node/{node_id}/vpn', 'ip_address')

has_file_server_flag = bool(rdb_ro.sismember(f'module/{module_id}/flags', 'file_server'))
if has_file_server_flag:
    rdb = agent.redis_connect(privileged=True)
    # Set metrics configuration and publish the events
    trx = rdb.pipeline()
    tdb = agent.read_envfile("timescaledb.env")
    # Provision the datasource
    ds_name = f"SambaAudit {os.environ['HOSTNAME']}"
    ui_name = rdb.get(f"module/{module_id}/ui_name")
    if ui_name is not None:
        ds_name += f" ({ui_name})"
    else:
        ds_name += f" ({module_id})"
    datasource_dict = {
        "apiVersion": 1,
        "datasources": [
            {
                "name": ds_name,
                "type": "postgres",
                "url": f"{ip_address}:15432",
                "user": "samba_audit",
                "secureJsonData": {
                    "password": tdb.get("SAMBA_AUDIT_PASSWORD")
                },
                "jsonData": {
                    "database": "samba_audit",
                    "sslmode": "disable",
                    "maxOpenConns": 100,
                    "maxIdleConns": 100,
                    "maxIdleConnsAuto": True,
                    "connMaxLifetime": 14400,
                    "postgresVersion": 17000,
                    "timescaledb": True
                }
            }
        ]
    }
    # Set the datasource in Redis
    trx.hset(f"module/{module_id}/metrics_datasources", "samba_audit", yaml.dump(datasource_dict))

    # List of dashboard files and their corresponding Redis keys
    for dashboard_key in ["samba_audit_statistics", "samba_audit_search"]:
        with open(f"../etc/grafana/{dashboard_key}.json", "r") as f:
            dashboard_content = f.read()
        trx.hset(f"module/{module_id}/metrics_dashboards", dashboard_key, dashboard_content)

    # Always publish the datasource and dashboard change events
    trx.publish(f"{agent_id}/event/metrics-datasource-changed", "{}")
    trx.publish(f"{agent_id}/event/metrics-dashboard-changed", "{}")
    trx.execute()
